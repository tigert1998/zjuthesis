\section{背景}
\label{background}

\subsection{边缘端AI加速器}
CPU和GPU被广泛用于边缘端神经网络推理。
但是，由于神经网络计算量的快速增长以及端侧计算场景对延时和能耗越来越高的要求，
许多专用的AI加速器被研发了出来，如一些综述文章\cite{chen2020survey, reuther2019survey}中所列出的。

这些加速器背后有几个主要的设计观念：
第一，由于神经网络推理的主要算子是卷积和矩阵乘法，
因而片上的晶体管将大多被用于提高数据层计算的并行性，而非缓存和乱序流水线\cite{jouppi2018domain}。
其次，加速器设计是硬件灵活性和效率之间的权衡。
一些指令集架构，例如Diannao系列\cite{chen2014diannao}，以优化高级算子为目标，如卷积和池化。
这样的设计在性能和功耗上是高效的，但是支持的神经网络算法却是非常局限的。
更多的指令集架构采用低级算子作为原语，如向量/矩阵计算，来支持更多的网络模型，
但这可能带来额外的功耗/面积开销\cite{liu2016cambricon}和编译复杂度。
另一个设计理念是量化。
FP32和FP64超出了神经网络推理的需要\cite{hennessy2019new}。
因而边缘AI加速器往往采用INT8，INT16或FP16进行推理。

下文中，我们将简要介绍本文评估的多种工业级AI加速器的主要特点（todo）。
节todo中将提供更多的信息。
这些加速器是大多是厂商专有的，公开的描述资料很少。

\paragraph{AI加速器}
Canaan开发的Kendryte KPU\cite{k210}针对边缘端机器视觉任务做了优化。
与Diannao相似，KPU在硬件上实现了卷积+批归一化+激活函数+池化的固定管线。
因而其他的神经网络结构需要通过人工或编译器修改达到芯片的要求。
其声称的算力是0.576 TOPs/s，功耗是300 mW。

Google Edge TPU\cite{jouppi2018domain}使用了CISC风格的专为神经网络设计的指令集架构，
支持指令如读取权重，执行矩阵乘法和卷积。
该芯片的核心组件是矩阵乘法计算单元，提供了每时钟周期$256\times 256$的8位乘加运算。
它的脉动阵列结构\cite{kung1979systolic}支持在每次计算中，每个输入在回写内存之前只需要被读取一次。
其声称的峰值性能是4 TOPs/s，功耗是2 W。

高通Hexagon DSP 600系列\cite{dsp}的特点是具有被应用于图像和视觉任务的Hexagon向量扩展（HVX）。
它拥有32个1024位向量寄存器，并在它的VLIW指令中支持多达四个向量槽，因而每个周期可以处理4096位的数据。
Hexagon 68x系列可以达到256 GOPs/s的峰值性能。

Rockchip NPU\cite{rk3399pro}使用VeriSilicon的VIP8000。
VIP8000采用GPU的设计方法并接受OpenCL着色器代码。
它的每个核心都具有64个CNN专用处理单元（INT8），
以及一个支持浮点和整数计算的128位向量计算单元。
它拥有3 TOPs/s的峰值性能和1.3 W的功耗。

英特尔Movidius Myriad X VPU集成了16个SHAVE（流式混合架构向量引擎）内核和一个规格未知的神经网络计算引擎。
SHAVE核心\cite{shave}混合RISC/DSP/GPU的架构。
它具有32个128位寄存器，每个寄存器均可进行8/16/32位SIMD计算，并由可变长度VLIW指令控制。
在2 W的功耗下，VPU可以达到1 TOPs/s的神经网络推理性能。

\subsection{高效神经网络的设计与部署}
\label{nn design and deployment}

\paragraph{神经网络设计}
许多超参数包括网络结构，内核尺寸，输入/输出通道数，网络层数等都会影响神经网络的性能并使得设计空间更加庞大。
其中，通道数的配置以及算子/模块结构对于在资源受限平台上部署模型是至关重要的。

一个流行的启发式规则是``特征图边长减半，通道数加倍''。
它首先被VGG\cite{simonyan2014very}引入，
后来又被应用于许多其他的神经网络设计工作中，
例如ResNet\cite{he2016deep}和MobileNet\cite{howard2017mobilenets, sandler2018mobilenetv2}系列。
除了这种人为设计的启发式方法，许多基于剪枝和NAS（神经网络结构搜索）
\cite{he2018amc, lee2019device, liu2019metapruning}的方法
也提出了最优通道数的解法。

近年CNN的工作\cite{he2016deep, ma2018shufflenet, sandler2018mobilenetv2}
通常会设计一个高效的模块（todo），并在每一阶段中重复它。
ResNet\cite{he2016deep}使用残差模块和短路连接来达到令人印象深刻的精度。
DenseNet\cite{huang2017densely}通过添加更密集的层与层之间的全连接来改进ResNet。
为了在资源有限的边缘设备部署上网络，MobileNetV1\cite{howard2017mobilenets}
引入了深度可分离卷积以减少运算量。
MobileNetV2\cite{sandler2018mobilenetv2}引入了倒置残差和线性瓶颈模块。
ShuffleNetV1\cite{zhang2018shufflenet}使用了$1\times 1$组卷积和通道重排，
在保持良好准确性的同时极大地减少了计算量。
改进后的ShuffleNetV2\cite{ma2018shufflenet}去除了组卷积，
并在分析了移动端CPU的效率后重新调整了模块。
SENet\cite{hu2018squeeze}介绍了SE模块，该模块在占有极少计算量的基础上可以大幅度提高模型准确率。
MobileNetV3\cite{howard2019searching}和EfficientNet\cite{tan2019efficientnet}
集成了SE模块并提高了其效率。
MixConv\cite{tan2019mixconv}也是一个高效的模块，
它对特征图进行分组，并对不同组使用不同内核尺寸大小的逐通道卷积。

这些工作反映了高效神经网络设计的两个趋势。
首先是计算密集型的卷积被替换为其他访存密集型算子，例如通道重排。
第二是新算子被引入以提高准确率。
这些趋势可以有效地帮助提高CPU上的模型推理性能。
但是，当下主要用于加速卷积的AI加速器几乎无法适应这些趋势，并可能产生性能问题（todo）。

\paragraph{模型部署}
当专家完成神经网络模型的设计后，模型需要经过额外的部署过程来在目标设备上推理。
主流的神经网络开发框架（如TFLite）通常会执行以下三个主要步骤：
\begin{enumerate*}
    \item 将原始模型格式转换为当前部署框架的模型格式；
    \item 优化计算图，制定模型的执行计划或生成目标设备代码。
    其中最重要的图层次优化是算子融合。
    它将相邻算子（通常是卷积和逐元素算子）的计算合并在一起，减少了中间结果的访存开销。
    \item 将原始FP32模型量化到目标精度，比如INT8。
    这往往需要在计算图中添加Quantize、Requantize、Dequantize等算子（如图\ref{fig:pipeline}）。
    量化通常能减少模型大小和推理延时，但是往往也会造成精度损失。
\end{enumerate*}
