\section{背景}
\label{background}

\subsection{边缘端AI加速器}
CPU和GPU被广泛用于边缘端神经网络推理。
但是，由于神经网络计算量的快速增长以及端侧计算场景对延时和能耗越来越高的要求，
许多专用的AI加速器被研发了出来，如一些综述文章\cite{chen2020survey, reuther2019survey}中所列出的。

这些加速器背后有几个主要的设计观念：
第一，由于神经网络推理的主要算子是卷积和矩阵乘法，
因而片上的晶体管将大多被用于提高数据层计算的并行性，而非缓存和乱序流水线\cite{jouppi2018domain}。
其次，加速器设计是硬件灵活性和效率之间的权衡。
一些指令集架构，例如Diannao系列\cite{chen2014diannao}，以优化高级算子为目标，如卷积和池化。
这样的设计在性能和功耗上是高效的，但是支持的神经网络算法却是非常局限的。
更多的指令集架构采用低级算子作为原语，如向量/矩阵计算，来支持更多的网络模型，
但这可能带来额外的功耗/面积开销\cite{liu2016cambricon}和编译复杂度。
另一个设计理念是量化。
FP32和FP64超出了神经网络推理的需要\cite{hennessy2019new}。
因而边缘AI加速器往往采用INT8，INT16或FP16进行推理。

下文中，我们将简要介绍本文评估的多种工业级AI加速器的主要特点（todo）。
节todo中将提供更多的信息。
这些加速器是大多是厂商专有的，公开的描述资料很少。

\paragraph{AI加速器}
Canaan开发的Kendryte KPU\cite{k210}针对边缘端机器视觉任务做了优化。
与Diannao相似，KPU在硬件上实现了卷积、批标准化、激活函数、池化的固定管线。
因而其他的神经网络结构需要通过人工或编译器修改达到芯片的要求。
其声称的算力是0.576 TOPs/s，功耗是300 mW。

Google Edge TPU\cite{jouppi2018domain}使用了CISC风格的专为神经网络设计的指令集架构，
支持指令如读取权重，执行矩阵乘法和卷积。
该芯片的核心组件是矩阵乘法计算单元，提供了每时钟周期$256\times 256$的8位乘加运算。
它的脉动阵列结构\cite{kung1979systolic}支持在每次计算中，每个输入在回写内存之前只需要被读取一次。
其声称的峰值性能是4 TOPs/s，功耗是2 W。

高通Hexagon DSP 600系列\cite{dsp}的特点是具有被应用于图像和视觉任务的Hexagon向量扩展（HVX）。
它拥有32个1024位向量寄存器，并在它的VLIW指令中支持多达四个向量槽，因而每个周期可以处理4096位的数据。
Hexagon 68x系列可以达到256 GOPs/s的峰值性能。

Rockchip NPU\cite{rk3399pro}使用VeriSilicon的VIP8000。
VIP8000采用GPU的设计方法并接受OpenCL着色器代码。
它的每个核心都具有64个CNN专用处理单元（INT8），
以及一个支持浮点和整数计算的128位向量计算单元。
它拥有3 TOPs/s的峰值性能和1.3 W的功耗。

英特尔Movidius Myriad X VPU集成了16个SHAVE（流式混合架构向量引擎）内核和一个规格未知的神经网络计算引擎。
SHAVE核心\cite{shave}混合RISC/DSP/GPU的架构。
它具有32个128位寄存器，每个寄存器均可进行8/16/32位SIMD计算，并由可变长度VLIW指令控制。
在2 W的功耗下，VPU可以达到1 TOPs/s的神经网络推理性能。

\subsection{高效神经网络的设计与部署}