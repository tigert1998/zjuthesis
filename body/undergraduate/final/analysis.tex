\newcounter{finding}[section]
\newenvironment{finding}[1][]{
    \refstepcounter{finding}\par
    \medskip\textbf{发现\thefinding#1} 
    \rmfamily}{\medskip}

\section{硬件行为分析}
\label{analysis}
本节分析了七种处理器上的基准测试结果，并展示了神经网络与硬件行为的发现。
本文会对不寻常的结果，基于硬件特性、框架实现和神经网络结构给出详尽的解释。
评估维度包括通道数（节\ref{analysis:channels}）、
模块类型、卷积内核尺寸、激活函数（节\ref{analysis:op block}）和
量化算法（节\ref{analysis:model quantization}）。

\subsection{通道数}
\label{analysis:channels}

\inputbody{final/analysis_misc/conv_pics}

通道数是对高效神经网络调优的重要参数。
基本的一个直觉是更大的通道数意味着更多计算数，因此有着更长的推理时间。
本节将展示通道数变化时真实的卷积延时响应。

图\ref{fig:conv_cin_fixed}展示了在各个硬件上变化$C_{out}$导致的卷积延时变化（固定$C_{in}$和其他超参数）。

\begin{finding}
    除了KPU之外，卷积延时随着输出通道数以台阶的规律增长。
\end{finding}

根据表\ref{tab:calculation}所示，当其他超参数固定时卷积的计算复杂度是$O(C_{out})$。
然而，测量获得的真实延时显示出了阶梯式的规律，其背后的根本原因是处理器的数据并行化。
这些处理器往往采用向量/矩阵计算单元来加速张量计算。
为了充分利用这些计算单元，上层的神经网络框架需要将数据分区，并将输入张量扩展到特定倍数，从而产生了台阶式的延时变化。

接下来，我们将以CPU、GPU和DSP的结果为例来阐述这一现象，因为它们的框架是开源的。
在其他闭源的处理器上，类似的解释很可能也适用。
注意，下文的每一个实验都只展示了一组超参数配置的数据。

CPU：TFLite v2.1使用\textit{im2col}\cite{vasudevan2017parallel}
将图片扩展成矩阵，并以矩阵乘法的方式以进行卷积。
如图\ref{fig:cpuconv}所示，每个卷积滤波器的内核被展开成左操作数中的一列，
相应特征图的区域则被展开为右操作数的一列。
之后TFLite则调用ruy\cite{ruy}矩阵运算库计算卷积。

ruy的矩阵计算针对ARMv8-A指令集做了优化。
该指令集包括了32个128位SIMD（即Neon）寄存器\cite{armisa}。
为了更好地利用这些寄存器，
ruy在计算FP32精度时将矩阵计算的最小单位设为$(8,1)\times (1,8)\rightarrow (8,8)$。
计算中，向量寄存器V16至V31被用作$(8,8)$大小的结果累加器。
寄存器V0至V3被用作加载左操作数$(8,1)$以及右操作数$(8,1)$。
为了适应这个最小的计算单位，两个输入矩阵都被填充到8的倍数。
因此，当其他超参数固定并且只有输出通道数增加时，
延时如图\ref{fig:conv_cin_fixed:cpu}所示地台阶式增长，并且台阶长度为8。

GPU：如节\ref{measurement}所述，我们利用TFLite的OpenCL后端在Adreno GPU上测试。
OpenCL的计算模型要求将索引空间划分成工作组（即CUDA中的块）\cite{lee2019device}。
TFLite的实现中，卷积算子的索引空间就是如图\ref{fig:gpuconv}所示的输出特征图。
一个工作组是GPU SIMT并行化中的基本计算模块。
工作组中的所有工作项执行同样的着色器代码，使用同样的工作组屏障。
因为输出特征图需要被填充到整数个工作组，
所以图\ref{fig:conv_cin_fixed:gpu}中的延时也呈现出阶梯式上升的规律。

然而，GPU延时的台阶宽度并不像CPU那样是固定的。
这是因为工作组尺寸和向量寄存器不同，它是由框架根据计算量设定的。
一个适当的工作组尺寸是由多种硬件配置，如Warp大小、计算单元数或共享内存大小共同决定的。
因此，TFLite使用了穷尽搜索策略来寻找工作组尺寸，这就导致了变化的台阶宽度。

DSP：Hexagon DSP 600系列的向量寄存器宽度为1024位。
为了配合这一点，Hexagon NNLib设计了Depth32\cite{nnlib}数据格式，
并将一个三维张量$(H,W,C)$的基本计算模块设为$(1,4,32)$的尺寸。
在INT8精度下，每个模块正好占用$32\times 4\times 8=1024$位。
为了适应这种数据格式，框架把所有张量的宽度一维填充为4的倍数，以及把通道数的维度填充为32的倍数。
之后两个基本块输入被打包成一对，并送入两个流中执行。
这就是图\ref{fig:conv_cin_fixed:dsp}显示，DSP的延时随着通道数增加有一个宽度为64的台阶的原因。

出于类似的原因，图\ref{fig:conv_cin_fixed}中的除KPU之外的其他处理器也表现出台阶的规律。
在KPU上通道数和延时之间则呈现出线性关系。
我们推测其原因是KPU对每个通道逐一顺序计算，因而不需要填充。

上述详细的分析再次说明，要理解神经网络行为，就需要对神经网络框架和硬件有深入的了解。
这证明我们用基准测试的方法来填补神经网络研究与底层系统之间空白的必要性和有效性。
基于上述的发现，神经网络设计空间可以只保留每个台阶的最大的通道数，
以达到可能的更高准确度（更多的OPs），而且没有额外的延时开销。

我们还评估了$C_{in}$维度上的卷积延时变化（由于篇幅限制没有画图）。
除了DSP和VPU外，由于在输入张量的维度上没有填充
（如图\ref{fig:cpuconv}和图\ref{fig:gpuconv}所示），
卷积延时随$C_{in}$线性变化。

\subsection{算子和模块}
\label{analysis:op block}

\subsection{模型与量化算法}
\label{analysis:model quantization}