\section{神经网络设计上的案例研究}

\subsection{通道剪枝}
通道剪枝中逐层的通道剪枝率是很难选择的。
启发式的和基于NAS的方法都根据每层中各通道的重要性来设置通道配置。
这个过程需要大量的时间以达到最佳的准确度和效率平衡。

节\ref{analysis:channels}的发现表明，$C_{out}$的减少并不总是意味着延时的减少。
因此我们可以通过只选择延时台阶的最大通道数，并跳过台阶中的其他通道数来保持准确度、加速通道剪枝。

例如，MetaPruning\cite{liu2019metapruning}
对MobileNetV1中的每一层$l$，
在$[\lfloor 0.1C_{out}^l \rfloor, C_{out}^l]$的范围内，
以$\lfloor 0.03C_{out}^l \rfloor$为步长搜索$C_{out}$
（其中$C_{out}^l$是原始网络中第$l$层的通道数）。
对于输出张量为$112^2\times 32$的一层，
初始的步长是1，候选的通道数是30（从3到32）。
那么包含14层的MobileNetV1的搜索空间大小将大约是$30^{14}$。
幸运的是，本文的发现展示了，
在CPU上卷积的推理延时随$C_{out}$的减少是台阶式的，并且台阶的长度是8
（如图\ref{fig:conv_cin_fixed:cpu}所示）。
这将候选的通道数选择量从30减少到4（即8、16、24、32），
将搜索空间从$30^{14}$减少到$4^{14}$。
在单层中我们将通道数选择量降低到了原来的$7.5^{-1}$。
并且我们通过将总共的搜索空间大小降低到了原来的$10^{-12}$，来加速MobileNetV1的剪枝过程。

\subsection{可感知硬件神经网络结构搜索中的原则}