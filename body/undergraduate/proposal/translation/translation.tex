\cleardoublepage
\chapter{外文翻译}

\section*{摘要}

最近，将机器学习应用到各种各样的硬件设备中的需求越来越大。
当前的框架依赖于供应商提供的特定的算子库，而且仅仅针对服务器GPU进行优化。
将计算任务部署到新平台，如移动手机、嵌入式设备和硬件加速器（FPGA、ASIC）等，需要大量的手工优化工作。
针对如上现象，我们提出了TVM，一个使用了图级别和算子级别优化的编译器，来提供深度学习计算在不同硬件后端的性能可移植性。
TVM解决了深度学习中的优化问题，如高阶算子融合、映射到任意硬件原语和内存延迟隐藏。
它还通过采用新颖的、基于学习的代价模型来快速地探索代码优化，自动化了根据硬件特性的低级别程序的优化。
实验结果表明，TVM在不同硬件后端提供的性能，与当前最好的手动优化的对移动端CPU、GPU和服务端GPU的深度学习推理代码相媲美。
我们还展示了TVM在新的硬件加速器后端的能力，例如基于FPGA的通用深度学习加速器。
TVM是开源的，并在几个大公司的生产环境中使用。

\section{节标题}
