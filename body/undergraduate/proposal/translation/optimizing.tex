\section{优化计算图}
计算图是表示深度学习框架中程序的一种常用方法。图 显示了一个两层卷积神经网络的示例计算图表示。
这种高级表示形式与低级的编译器中间表示形式（IR）（例如LLVM）之间的主要区别在于，中间数据项是大型的多维张量。
计算图提供了算子的全局概览，但并不指定实现每个算子的方式。像LLVM IR一样，计算图可以被转换为等价的图
以应用优化。我们还利用深度学习工作负载中常见的特定张量形状来优化特定的固定的输入形状。

TVM利用一种计算图表示来应用高级优化：一个节点表示在张量或程序输入上的运算，而边表示运算之间的数据依存关系。
它实现了许多图级优化，包括：算子融合，将多个小算子融合在一起；常量折叠，将可以预先计算的图部分静态化，
从而节省执行成本；编译时内存分配计划，它预先分配内存以容纳每个中间张量；数据布局转换，
将内部数据布局转换为后端友好的形式。现在我们讨论算子融合和数据布局转换。

\paragraph{算子融合}
算子融合将多个算子组合成一个内核，而不是在运行时将中间结果保存在内存中。这种优化可以大大减少执行时间，
尤其是在GPU和专用加速器中。具体来说，我们把图算子分成四类：
\begin{enumerate*}
    \item Injective（一对一映射，比如加法）；
    \item Reduction（比如求和）；
    \item Complex-Out-Fusable（可以把一对一映射算子融合到输出，比如二维卷积）；
    \item Opaque（无法被融合的，比如排序算子）。
\end{enumerate*}
我们提供了融合这些算子的通用规则，如下所示：多个Injective算子可以被合并成一个Injective算子。
可以将输入的Injective算子和Reduction算子（例如，融合放缩算子和求和算子）融合在一起。
比如二维卷积之类的算子是Complex-Out-Fusable算子，我们可以将一对一映射算子融合到其输出。
我们可以应用这些规则将计算图转换为融合版本。图 展示了此优化对不同工作负载的影响。
我们发现，通过减少内存访问，融合算子可产生高达1.2倍至2倍的加速比。

\paragraph{数据布局转换}
有多种方法可以在计算图中存储给定张量。最常见的数据布局选择是列优先和行优先。
实际上，我们可能更喜欢使用更复杂的数据布局。例如，深度学习加速器可能会利用$4\times 4$矩阵运算，
要求将数据分块为$4\times 4$的块以优化内存空间局部性。

数据布局优化转换计算图，来更好地针对特定硬件使用内部数据布局。
首先，在特定内存层次结构的约束下，为每个算子指定较优的数据布局。
然后，如果一个张量的生产者和消费者的数据布局不匹配，我们将在它们之间执行适当的布局转换。

虽然高级图优化可以极大地提高深度学习工作负载的效率，但它们仅与算子库一样有效。
当前，很少有支持算子融合的深度学习框架需要算子库来提供融合的实现。随着更多的算子被引入代码库，
可能的融合内核数量会急剧增长。当针对越来越多的硬件后端时，手动实现融合算子的方法将不可持续，
因为所需的融合模式数量、数据布局、类型和加速器硬件内参在组合式增长。
对于程序和每个后端所需的各种算子，手工实现算子内核是不可行的。为此，我们接下来提出一种代码生成方法，
该方法可以为给定模型的算子生成各种可能的实现。
