\section{生成张量操作}
TVM给每个硬件后端生成许多高效的实现并选择其中一个优化的实现，来为每个算子生成高效的代码。
此过程建立在Halide的解耦描述与计算规则（或者调度优化）思想的基础上，
并将其扩展为支持新的优化（嵌套并行性，张量化和延迟隐藏）和各种硬件后端。
现在，我们重点介绍TVM特性。

\subsection{张量表达式和调度空间}
我们引入了一个张量表达式语言来支持自动代码生成。与不透明的高级计算图表示不同，
在张量表达式中，每个运算都是用索引公式语言来表达的。以下代码显示了一个张量表达式示例，
用于计算转置矩阵乘法：

\begin{lstlisting}[language={Python}]
m, n, h = t.var('m'), t.var('n'), t.var('h')
A = t.placeholder((m, h), name='A')
B = t.placeholder((n, h), name='B')
k = t.reduce_axis((0, h), name='k')
C = t.compute((m, n), lambda y, x:
    t.sum(A[k, y] * B[k, x], axis=k)) 
\end{lstlisting}

每个计算操作都指定输出张量的形状，描述了如何计算其中的每个元素。
我们的张量表达式语言支持常见的算术和数学运算，并涵盖了常见的深度学习算子。
该语言没有指定循环结构和许多其他执行细节，它为添加各种后端的硬件优化提供了灵活性。
我们采用了Halide中解耦计算/调度的思想，使用调度来表示从张量表达式到低级代码的过程。
对同一个函数，存在许多合法的调度。

我们通过逐步应用保持等效性的基本转换（调度原语）来构建调度。
图 显示了在专用加速器上调度矩阵乘法的示例。
TVM内部在应用基本转换时会使用数据结构来跟踪循环结构和其他信息。
然后，这些信息可以帮助为给定的最终调度生成底层代码。

我们的张量表达式继承自Halide，Darkroom和TACO。
它的增强功能主要包括对下面讨论的对新调度优化的支持。
为了在许多后端上实现高性能，我们必须支持足够的调度原语，以涵盖不同硬件后端上的各种优化。
图 总结了算子的代码生成过程和TVM支持的调度原语。
我们重用Halide中有用的原语和低层次循环AST，并引入新的原语来优化GPU和加速器性能。
新的原语是实现最佳GPU性能所必需的，并且对于硬件加速器至关重要。
CPU，GPU，类TPU的加速器是深度学习的三种重要的硬件类型。
本节介绍了针对CPU，GPU和类TPU的加速器的新的优化原语，而第\ref{automating}节
则说明了如何自动得出高效的调度。

\subsection{合作的嵌套循环}

\subsection{张量化}

\subsection{显式内存延时隐藏}