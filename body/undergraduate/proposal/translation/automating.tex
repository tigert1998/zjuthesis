\section{自动优化}
\label{automating}
给定多样的调度原语集，我们剩下的问题是为深度学习模型的每一层找到最佳的算子实现。
TVM为每一层模型在不同输入和数据布局下都创建专门的算子。
这种专门化提供了显著的性能优势（手工优化的代码只能针对一小部分输入和数据布局），但是这也带来了自动化方面的挑战。
系统需要选择调度优化（比如修改循环顺序或针对内存层次进行优化），和特定调度的参数，例如分块大小和循环展开因子。
这样组合式的选择为每个硬件后端创建了一个庞大的算子实现空间。
为了应对这一挑战，我们构建了一个具有两个主要组件的自动化调度优化器：
一个提出新配置的调度探索器，和一个预测配置性能的深度学习代价模型。
本节介绍了这些组件以及TVM的自动优化流程（图 ）。

\subsection{调度空间规范}
我们构建了一个调度模板规范接口，帮助开发人员在调度空间中声明配置。 
模板规范允许在指定可能的调度时根据需要引入开发人员的特定领域知识。
我们还为每个硬件后端创建了一个通用的主模板，该模板根据使用张量表达语言表达的计算描述自动提取可能的配置。
在高层次上，我们将尽可能地考虑许多配置，并让优化器管理选择负担。
因此，在我们的实验中，优化器必须为现实世界中的深度学习任务搜索数十亿种可能的配置。

\subsection{基于机器学习的代价模型}
从较大配置空间中找到最佳调度的一种方法是通过黑盒优化（即自动调整）。
该方法经常被用于优化高性能计算库。
但是，这样的优化需要大量的实验才能找到良好的配置。

另一种方法是使用预先定义的代价模型，以指导特定硬件后端的搜索，而不是运行所有可能性并评估它们的性能。
理想情况下，一个理想的代价模型应考虑所有影响性能的因素：内存访问模式，数据重用，流水线数据依赖和线程化模式等。
不幸的是，由于现代硬件的日益复杂，这种方法是相当麻烦的。
此外，如果使用这样的方法，则每个新硬件都需要一个新的预定义成本模型。

\begin{table}[htbp]
\small
\begin{tabular}{ccccc}
    \hline
    方法类型 & 数据成本 & 模型偏差 & 是否需要硬件信息 & 是否学习历史数据 \\
    \hline
    黑盒自动优化 & 高 & 无 & 否 & 否 \\
    预先定义的代价模型 & 无 & 高 & 是 & 否 \\
    \textbf{基于机器学习的方法} & \textbf{低} & \textbf{低} & \textbf{否} & \textbf{是} \\
    \hline
\end{tabular}
\caption{\label{tab:methods}自动化方法的比较。模型偏差指建模导致的不精确性。}
\end{table}

相反，我们采用统计的方法来解决成本建模问题。
在这种方法中，调度管理器会提出一些配置，这些配置有可能提高算子的性能。
对于每个调度配置，我们使用基于机器学习的模型，该模型预测降低过的循环程序在给定硬件后端的运行时间。
模型使用在探索期间收集的运行时测量数据进行训练，而不需要用户输入详细的硬件信息。
当我们在优化过程中探索更多配置时，我们会周期性地更新模型，这也会提高预测其他相关工作负载的准确性。
这样以来，随着更多的性能测试，机器学习模型的质量也会逐渐提高。
表\ref{tab:methods}总结了自动化方法之间的主要区别。
基于机器学习的成本模型可以在自动优化和预定义成本模型之间取得平衡，并且可以从相关工作负载的历史性能数据中受益。

% \paragraph{机器学习模型设计选择}
% 选择计划浏览器将使用哪种机器学习模型时，我们必须考虑两个关键因素：质量和速度。
% 计划浏览器经常查询成本模型，这会因模型预测时间和模型重新建立时间而产生开销。
% 为了使这些开销有用，这些开销必须小于在实际硬件上测量性能所需的时间，该时间取决于特定工作负载/硬件目标的秒数级。
% 这种速度要求将我们的问题与传统的超参数调整问题区分开，传统的超参数调整问题相对于模型开销而言，
% 执行测量的成本非常高，并且可以使用更昂贵的模型。
% 除了选择模型之外，我们还需要选择一个目标函数来训练模型，例如配置的预测运行时间中的错误。
% 但是，由于资源管理器仅根据预测的相对顺序（A的运行速度比B快）选择了最高的候选者，因此不会直接预测绝对执行时间。
% 相反，我们使用客观目标来预测运行时成本的相对顺序。我们在机器学习优化器中实现所有模型类型。
% 我们建立了基于树的梯度提升模型（基于XGBoost [8]），该模型基于从循环程序中提取的特征进行预测；
% 这些功能包括在每个循环级别的每个存储器缓冲区的存储器访问计数和重用率，
% 以及循环注释的单次编码，例如``矢量化''，``展开''和``并行''。
% 我们还评估了一个神经网络模型，该模型使用TreeRNN [38]来总结循环程序的AST，而无需进行特征工程。
% 图13总结了成本模型的工作流程。我们发现，树增强和TreeRNN具有相似的预测质量。
% 但是，前者执行预测的速度快一倍，并且训练时间更少。结果，我们在实验中选择了梯度树增强作为默认成本模型。
% 尽管如此，我们认为这两种方法都是有价值的，并且有望在这个问题上进行进一步的研究。
% 平均而言，树增强模型可以在0.67毫秒内完成预测，比运行实际测量快数千倍。
% 图12将基于机器学习的优化器与黑盒自动调整方法进行了比较。
% 前者比后者能更快地找到更好的配置。

% \subsection{调度探索}
% 一旦选择了成本模型，我们就可以使用它来选择有前途的配置，以对其进行迭代的实际测量。
% 在每次迭代中，资源管理器都会使用机器学习模型的预测来选择要在其上进行测量的一组候选对象。
% 然后将收集的数据用作训练数据以更新模型。如果没有初始培训数据，则可以随机选择勘探人员。
% 最简单的探索算法会枚举并运行整个模型，通过成本模型，选择排名前k位的预测执行者。
% 但是，这种策略在较大的搜索空间中变得棘手。
% 相反，我们运行并行模拟退火算法[22]。
% 资源管理器从随机配置开始，然后在每个步骤中随机漫游到各个配置。
% 如果成本按照成本模型的预测降低，则此转换成功。如果目标配置的成本较高，则可能会失败（拒绝）。
% 如成本模型所预测的，随机游走到融合配置的标杆成本。
% 勘探状态在成本模型更新中持续存在；这些更新之后，我们将从上一个配置继续。

% \subsection{分布式设备池和远程过程调用}
% 分布式设备池可扩展多个优化作业之间硬件可试用的可修复细粒度资源共享的运行。
% TVM实现了一个基于RPC的定制的分布式设备池，该池使客户端能够在特定类型的设备上运行程序。 
% 我们可以使用此接口在主机编译器上编译程序，请求远程设备，运行远程运行，并在主机上以相同的脚本访问结果。 
% TVM的RPC支持动态上传，并运行使用其运行时约定的交叉编译模块和功能。 
% 结果，相同的基础架构可以执行单个工作负载优化和端到端图形推断。 
% 我们的方法可以自动跨多个设备进行编译，运行和配置步骤。 
% 这种基础结构采用了特别关键的嵌入式设备，传统上这些设备需要繁琐的手动工作才能进行交叉编译，代码部署和测量。