\section{测量方法}
\subsection{基准测试配置集合}
本项目计划从如下的几个方面研究不同神经网络在不同硬件上的执行效率，从而研究不同AI芯片的特性：
\begin{enumerate}
    \item 卷积和逐通道卷积（Depthwise Convolution）算子使用不同的输入输出通道数参数在不同硬件上的执行效率；
    \item 神经网络基本组成算子用不同的参数在不同硬件上的执行效率；
    \item 神经网络基本组成模块（比如深度可分离卷积、MobileNet V2中提出的反向残差模块等）用不同的参数在不同硬件上的执行效率；
    \item 不同的SOTA（State Of The Art）模型在不同硬件上使用不同的量化精度对推理准确率、推理速度的影响。
\end{enumerate}

\paragraph{变通道数测试}
因为卷积和逐通道卷积算子在卷积神经网络中起到了重要的特征提取作用，而且也占有了比较大的运算量，所以
本项目会着重测量这两个算子在不同通道数下的执行效率。

对于卷积算子，我们会选择三种通道数参数空间：
\begin{enumerate*}
    \item 输入通道数等于输出通道数；
    \item 输入通道数固定，输出通道数变化；
    \item 输出通道数固定，输入通道数变化。
\end{enumerate*}
对于逐通道卷积我们选择输入通道数等于输出通道数。
本项目对任意一个步长$\in \{1,2\}$，内核尺寸$\in \{1,3,5,7\}$的卷积、逐通道卷积都会在上述的
一个范围内的通道数内做测试。

\paragraph{多种算子和模块测试}
我们选择了卷积、逐通道卷积、扩张卷积（Dilated Convolution）、分组卷积（Grouped Convolution）、加法、
连接（Concatenation）、全局池化、全连接、通道重排（Shuffle）、混合卷积（Mix Convolution\cite{tan2019mixconv}）
作为待测的算子。另外，我们选择了
MobileNet V1\cite{howard2017mobilenets}、MobileNet V2\cite{sandler2018mobilenetv2}、
ShuffleNet V1\cite{zhang2018shufflenet}、ShuffleNet V2\cite{ma2018shufflenet}、
ResNet\cite{he2016deep}、DenseNet\cite{huang2017densely}
这些网络的基本构成模块作为模块的测试。

对于每个算子或模块，我们选择了输入特征图尺寸$\in \{224,112,56,28,14,7\}$，
步长$\in \{1,2\}$，内核尺寸$\in \{1,3,5,7\}$，分组$\in \{2,3,4,8\}$作为采样空间。

\paragraph{多种模型结合不同量化精度测试}
在该测试中我们选择了各种SOTA模型，包括了手工设计的模型和经过AutoML生成的模型，
比如MobileNet系列、ShuffleNet系列、FBNet\cite{wu2019fbnet}、ProxylessNas\cite{cai2018proxylessnas}等。
我们评估了这些模型在不同硬件上用不同的推理引擎和不同的量化方法得到的在ImageNet\cite{deng2009imagenet}验证集上
的精度和性能数据。

\subsection{硬件测量方法}
本研究使用了若干边缘端AI芯片作为研究对象，如：
\begin{itemize}
    \item Arm CPU
    \item Snapdragon Adreno GPU
    \item Snapdragon Hexagon DSP
    \item Rockchip RK1808计算棒
    \item Rockchip RK3399Pro NPU
    \item Intel Movidius计算棒
    \item Google Edge TPU
\end{itemize}

\paragraph{Arm CPU}
我们使用TensorFlow Lite R2.1（编译时使用参数Arm 64）进行基准测试。
我们在测试时把CPU的频率固定在了最高频保证延时和CPU频率无关。

\paragraph{Adreno GPU}
我们使用TensorFlow Lite R2.1提供的GPU代理进行基准测试。TensorFlow Lite的GPU代理使用了OpenCL实现。
本项目修改了部分TensorFlow Lite的GPU代理代码，使得CPU和GPU之间内存拷贝的时间，GPU上的内存布局转换的时间
可以和用于执行算子的OpenCL内核（Kernel）运行时间分开，从而达到分开记时的效果。

另外，OpenCL内核执行需要指定工作组尺寸（Work Group Size），该参数对GPU性能调优很重要，它控制了GPU任务的线程数。
TensorFlow Lite的GPU代理实现是每一层被融合过的算子会交由一个OpenCL内核执行。
而每一层的工作组尺寸都会在推理的初始化阶段被决定，这一过程也叫工作组尺寸调优。
调优的方式分为穷尽搜索（Exhaustive Tuning）和快速搜索（Fast Tuning）。
前者会在初始化阶段穷尽测试可能的工作组尺寸并选择最快的，后者会通过启发式的算法快速选择一个尺寸。
我们修改了TensorFlow Lite的代码使得我们可以手动指定每一层算子的OpenCL内核的工作组尺寸，
或者是指定TensorFlow Lite GPU代理的工作组尺寸调优方案。

\paragraph{Rockchip RK1808计算棒、RK3399Pro NPU}
Rockchip提供了闭源的神经网络编译器和神经网络推理框架RKNN。
RKNN提供了对每层神经网络延时分析的功能。本项目在这两个硬件平台上利用RKNN进行基准测试。

\paragraph{Google Edge TPU}
Edge TPU要求使用TensorFlow Lite模型，并且模型需要经过八位整数量化和Edge TPU的编译器编译。
鉴于TPU在TensorFlow Lite上的代理是闭源的，本项目直接对整个代理的耗时基准测试。

\subsection{基准测试平台}
根据上述的不同硬件的测试要求，以及不同的测试项目之间的差异，本项目计划完成一个一体化的测试平台，
以应对多样化的测试需求。我们根据需求，设计如下的基类：AccuracyTester，AccuracyEvaluator，
DataPreparer，LatencyTester，LatencyEvaluator，Connection，Sampler。它们各自有如下的职能：

\paragraph{AccuracyTester}
用于控制准确率测试的节奏。节奏对一部分存储空间较小的测试机（比如手机）比较重要，
因为在容量较小的情况下，需要把维持在测试机上占有的数据集空间大小。该类会逐步分批次
拷贝数据集并加载模型进行测试，下一个批次的测试数据集可以选择覆盖上批次数据集以占有尽量少的空间。
该类测试的模型详细信息来自于Sampler子类的采样。该类会先调用DataPreparer进行数据集
准备工作，再调用AccuracyEvaluator在各类硬件上测试准确率。

\paragraph{AccuracyEvaluator}
实现了在不同硬件平台上的准确率测量。不同的硬件要求使用不同的推理框架，该类利用多态
特性，提供了统一的接口利用准备好的数据集测试不同的硬件上模型的准确率。

\paragraph{DataPreparer}
实现了在不同平台上的准确率数据集准备工作。因为不同硬件的配套SDK要求的模型和数据集格式有差异，
所以该类提供统一的接口整理模型与用于测试的ImageNet图片集和标签，并通过Connection类传输到目标
测试机上。

\paragraph{LatencyTester}
该类以及其子类实现了各种不同的测试。比如单层算子测试会生成对应硬件的模型并传送到测试机上进行测试。
某些需要额外处理的硬件测试可以通过扩展该类的子类完成额外的工作。该类会调用LatencyEvaluator
完成延时数据的获取。

\paragraph{LatencyEvaluator}
实现了在不同硬件平台上的延时数据测量。不同的硬件要求使用不同的推理框架，该类利用多态
特性，提供了统一的接口测试在不同的硬件上推理模型的延时。该类支持编译未经训练的
TensorFlow计算图到其他各种硬件模型。

\paragraph{Connection}
用于连接多样化的目标测试机，使得存放测试代码的宿主机可以通过统一的接口进行访问远程的测试机器。
比如Edge TPU开发板需要配置在Debian的环境，而宿主机需要通过SSH连接传输数据；而Arm CPU和
Adreno GPU上的测试需要通过ADB连接手机进行测试。

\paragraph{Sampler}
用于生成测试的集合。该类提供给AccuracyTester和LatencyTester以需要测试的数据点，比如ImageNet
模型的输入输出节点，或者需要测量的算子、单元的参数信息。
