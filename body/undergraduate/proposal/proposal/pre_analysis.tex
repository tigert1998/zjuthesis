\section{可行性分析}
针对多种不同的硬件，开题报告都预先做了一些前置性、探索性的基准测试和分析。
在这里我们把它们分成几大类：向量化的架构（Hexagon DSP，Movidius计算棒）、
通用处理器（Arm CPU）、SIMT（Same Instruction Multiple Threads）架构（Adreno GPU）、NPU（RK1808计算棒）。
经过分析，我们认为理论复杂度和实机延时之间的差距是非平凡的，值得深入研究和分析。

\subsection{向量化硬件架构的测试与特性分析}
在Hexagon DSP上，首先我们测量了卷积算子在各个不同的参数下的延时。
我们发现Hexagon DSP在大部分输入特征图尺寸下，固定输入通道数变化输出通道数、固定输出通道
数变化输入通道数，$1\times 1$卷积的延时都会随着通道数的递增呈现出阶梯化上升的趋势，并且这个阶梯的长度固定
为32。我们翻阅了Hexagon DSP上神经网络推理框架SNPE（Snapdragon Neuron Processing Engine）的开源代码，
发现其中$1\times 1$卷积实现会把输入特征图的输入输出通道数扩展为32的倍数，把宽度扩展为4的倍数。
这样做是因为Hexagon DSP具有4个硬件线程，每个线程在每个周期内可以完成32个向量乘法操作，每个向量的长度是32。
推理软件选择扩展输入特征图，是因为这样可以更容易利用好DSP的硬件并行性。这就是上文所阐述的延时阶梯状上升的原因。

\subsection{通用处理器的测试与特性分析}
我们预先测量了$1\times 1$卷积在高通骁龙855 CPU上的表现。经过测试，我们发现：在固定输入通道数，
改变输出通道数时，延时会表现出随着通道数阶梯状上升的趋势，并且阶梯长度固定是8；在固定输出通道数，改变输入通道数时，
延时会随着计算量增加近似线性增长。在阅读相关代码之后，我们发现TensorFlow Lite利用了Arm的NEON加速
（Arm上的SIMD指令集）实现了自己的GEMM（通用矩阵计算）库RUY。而卷积算子会被im2col算法转成矩阵乘法操作
交给RUY运算。而RUY在实现矩阵乘法的时候，为了更好地利用NEON的SIMD特性，会在输出通道数的维度上扩展到8的倍数，
而在输入通道数上没有额外的扩展。因而体现出了在输出通道数上有延时台阶式上升的现象。

\subsection{SIMT架构硬件的测试与特性分析}
我们把Adreno 640作为SIMT架构的代表，并在该GPU上测试了$1\times 1$卷积。
我们设置TensorFlow Lite工作组尺寸调优方案为穷尽搜索。
经过测试我们发现当固定输入通道数，修改输出通道数的时候延时随着通道数增长阶梯式地上升，
而且这个阶梯长度在输入长宽为7时长达几百通道数。但是固定输出通道数修改输入通道数时，延时却随着通道数增长近似
线性地增加（每4个通道一采样）。在阅读过卷积算子的OpenCL内核实现之后，
我们发现卷积算子的内核实现是在输出特征图上划分并行的任务，比如每个线程负责$h\times w\times c$的输出神经元计算，
而每个线程内部则会串行地计算结果。OpenCL的并行能力来源于一组线程（Warp）的同时计算，在这里也就体现为一个区域的
输出神经元的结果计算。因为移动端GPU受限于计算单元（Compute Unit）数量、每线程的私有内存大小、
每线程占有寄存器数量，所以在GPU上一个批次执行的线程数量是有限的。所以当修改输出通道数时，线程数量会增加，
这样的增加要累计到一个批次才能引发延时的大幅度增加。然而修改输入通道数时，每线程的工作量会增加，所以
延时会线性地增长。

\subsection{NPU架构硬件的测试与特性分析}
我们预先测量了RK1808计算棒在$1\times 1$卷积算子上的表现。我们发现计算棒不论在固定输入通道数还是在固定输出通道数
的情况下延时都会表现出相对线性的随通道数增长，但是存在许多参数值，延时会大幅度偏离线性的范畴。由于RK1808上的
NPU架构信息偏少，编译器不开源，延时曲线背后的原因暂时没有合理的解释。