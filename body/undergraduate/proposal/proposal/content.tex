\section{项目的主要内容和技术路线}

\subsection{主要研究内容}
本项目计划从如下的几个方面研究不同神经网络在不同硬件上的执行效率，从而研究不同AI芯片的特性：
\begin{enumerate}
    \item 卷积和逐通道卷积（Depthwise Convolution）算子使用不同的输入输出通道数参数在不同硬件上的执行效率；
    \item 神经网络基本组成算子用不同的参数在不同硬件上的执行效率；
    \item 神经网络基本组成模块（比如深度可分离卷积、MobileNet V2中提出的反向残差模块等）用不同的参数在不同硬件上的执行效率；
    \item 不同的SOTA（State Of The Art）模型在不同硬件上使用不同的量化精度对推理准确度、推理速度的影响。
\end{enumerate}

本研究计划通过分析实际执行效率和理论计算复杂度之间的差别，结合硬件架构，理解边缘端硬件在并行性、资源调度方面的特性，
从而对今后边缘端友好的神经网络设计有所启发。

\subsection{技术路线}

\subsubsection{基准测试配置集合}

\paragraph{变通道数测试}
因为卷积和逐通道卷积算子在卷积神经网络中起到了重要的特征提取作用，而且也占有了比较大的运算量，所以
本项目会着重测量这两个算子在不同通道数下的执行效率。

对于卷积算子，我们会选择三种参数空间：% TODO

\paragraph{多种算子测试}

\paragraph{多种模块测试}

\paragraph{多种模型结合不同量化精度测试}

\subsubsection{硬件测量方法}
本研究使用了若干边缘端AI芯片作为研究对象，如：
\begin{itemize}
    \item Arm CPU
    \item Snapdragon Adreno GPU
    \item Snapdragon Hexagon DSP
    \item Rockchip RK1808计算棒
    \item Rockchip RK3399Pro NPU
    \item Intel Movidius计算棒
    \item Google Edge TPU
\end{itemize}

\paragraph{Arm CPU}
我们使用TensorFlow Lite R2.1（编译时使用参数Arm 64）进行基准测试。
我们在测试时把CPU的频率固定在了最高频保证延时和CPU频率无关。

\paragraph{Adreno GPU}
我们使用TensorFlow Lite R2.1提供的GPU代理进行基准测试。TensorFlow Lite的GPU代理使用了OpenCL实现。
本项目修改了部分TensorFlow Lite的GPU代理代码，使得CPU和GPU之间内存拷贝的时间，GPU上的内存布局转换的时间
可以和用于执行算子的OpenCL内核（Kernel）运行时间分开，从而达到分开记时的效果。

另外，OpenCL内核执行需要指定工作组尺寸（Work Group Size），该参数对GPU性能调优很重要，它控制了GPU任务的线程数。
TensorFlow Lite的GPU代理实现是每一层被融合过的算子会交由一个OpenCL内核执行。而每一层的工作组尺寸都会
在推理的初始化阶段被决定，这一过程也叫工作组尺寸调优。调优的方式分为穷尽搜索（Exhaustive Tuning）和快速搜索（Fast Tuning）。
前者会在初始化阶段穷尽测试可能的工作组尺寸并选择最快的，后者会通过启发式的算法快速选择一个尺寸。
我们修改了TensorFlow Lite的代码使得我们可以手动指定每一层算子的OpenCL内核的工作组尺寸，
或者是指定TensorFlow Lite GPU代理的工作组尺寸调优方案。

\paragraph{Rockchip RK1808计算棒、RK3399Pro NPU}
Rockchip提供了闭源的神经网络编译器和神经网络推理框架RKNN。
RKNN提供了对每层神经网络延时分析的功能。本项目在这两个硬件平台上利用RKNN进行基准测试。

\paragraph{Google Edge TPU}
Edge TPU要求使用TensorFlow Lite模型，并且模型需要经过八位整数量化和Edge TPU的编译器编译。
鉴于TPU在TensorFlow Lite上的代理是闭源的，本项目直接对整个代理的耗时基准测试。

\subsubsection{基准测试平台}
根据上述的不同硬件的测试要求，以及不同的测试项目之间的差异，本项目计划完成一个一体化的测试平台，
以应对多样化的测试需求。我们根据需求，设计如下的基类：AccuracyTester，AccuracyEvaluator，
DataPreparer，LatencyTester，LatencyEvaluator，Connection，Sampler。它们各自有如下的职能：

\paragraph{AccuracyTester}
用于控制精确度测试的节奏。节奏对一部分存储空间较小的测试机（比如手机）比较重要，
因为在容量较小的情况下，需要把维持在测试机上占有的数据集空间大小。该类会逐步分批次
拷贝数据集并加载模型进行测试，下一个批次的测试数据集可以选择覆盖上批次数据集以占有尽量少的空间。
该类测试的模型详细信息来自于Sampler子类的采样。该类会先调用DataPreparer进行数据集
准备工作，再调用AccuracyEvaluator在各类硬件上测试精确度。

\paragraph{AccuracyEvaluator}
实现了在不同硬件平台上的精确度测量。不同的硬件要求使用不同的推理框架，该类利用多态
特性，提供了统一的接口利用准备好的数据集测试不同的硬件上模型的精确度。

\paragraph{DataPreparer}
实现了在不同平台上的精确度数据集准备工作。因为不同硬件的配套SDK要求的模型和数据集格式有差异，
所以该类提供统一的接口整理模型与用于测试的ImageNet图片集和标签，并通过Connection类传输到目标
测试机上。

\paragraph{LatencyTester}
该类以及其子类实现了各种不同的测试。比如单层算子测试会生成对应硬件的模型并传送到测试机上进行测试。
某些需要额外处理的硬件测试可以通过扩展该类的子类完成额外的工作。该类会调用LatencyEvaluator
完成延时数据的获取。

\paragraph{LatencyEvaluator}
实现了在不同硬件平台上的延时数据测量。不同的硬件要求使用不同的推理框架，该类利用多态
特性，提供了统一的接口测试在不同的硬件上推理模型的延时。该类支持编译未经训练的
TensorFlow计算图到其他各种硬件模型。

\paragraph{Connection}
用于连接多样化的目标测试机，使得存放测试代码的宿主机可以通过统一的接口进行访问远程的测试机器。
比如Edge TPU开发板需要配置在Debian的环境，而宿主机需要通过SSH连接传输数据；而Arm CPU和
Adreno GPU上的测试需要通过ADB连接手机进行测试。

\paragraph{Sampler}
用于生成测试的集合。该类提供给AccuracyTester和LatencyTester以需要测试的数据点，比如ImageNet
模型的输入输出节点，或者需要测量的算子、单元的参数信息。

\subsection{可行性分析}
针对多种不同的硬件，开题报告都预先做了一些前置性、探索性的基准测试和分析。
在这里我们把它们分成几大类：向量化的架构（Hexagon DSP，Movidius计算棒）、
通用处理器（Arm CPU）、SIMT（Same Instruction Multiple Threads）架构（Adreno GPU）、NPU（RK1808计算棒）。
经过分析，我们认为理论复杂度和实机延时之间的差距是非平凡的，值得深入研究和分析。

\subsubsection{向量化硬件架构的测试与特性分析}
在Hexagon DSP上，首先我们测量了卷积算子在各个不同的参数下的延时。
我们发现Hexagon DSP在大部分输入特征图尺寸下，固定输入通道数变化输出通道数、固定输出通道
数变化输入通道数，$1\times 1$卷积的延时都会随着通道数的递增呈现出阶梯化上升的趋势，并且这个阶梯的长度固定
为32。我们翻阅了Hexagon DSP上神经网络推理框架SNPE（Snapdragon Neuron Processing Engine）的开源代码，
发现其中$1\times 1$卷积实现会把输入特征图的输入输出通道数扩展为32的倍数，把宽度扩展为4的倍数。
这样做是因为Hexagon DSP具有4个硬件线程，每个线程在每个周期内可以完成32个向量乘法操作，每个向量的长度是32。
推理软件选择扩展输入特征图，是因为这样可以更容易利用好DSP的硬件并行性。这就是上文所阐述的延时阶梯状上升的原因。

\subsubsection{通用处理器的测试与特性分析}
我们预先测量了$1\times 1$卷积在高通骁龙855 CPU上的表现。经过测试，我们发现：在固定输入通道数，
改变输出通道数时，延时会表现出随着通道数阶梯状上升的趋势，并且阶梯长度固定是8；在固定输出通道数，改变输入通道数时，
延时会随着计算量增加近似线性增长。在阅读相关代码之后，我们发现TensorFlow Lite利用了Arm的NEON加速
（Arm上的SIMD指令集）实现了自己的GEMM（通用矩阵计算）库RUY。而卷积算子会被im2col算法转成矩阵乘法操作
交给RUY运算。而RUY在实现矩阵乘法的时候，为了更好地利用NEON的SIMD特性，会在输出通道数的维度上扩展到8的倍数，
而在输入通道数上没有额外的扩展。因而体现出了在输出通道数上有延时台阶式上升的现象。

\subsubsection{SIMT架构硬件的测试与特性分析}
我们把Adreno 640作为SIMT架构的代表，并在该GPU上测试了$1\times 1$卷积。
我们设置TensorFlow Lite工作组尺寸调优方案为穷尽搜索。
经过测试我们发现当固定输入通道数，修改输出通道数的时候延时随着通道数增长阶梯式地上升，
而且这个阶梯长度在输入长宽为7时长达几百通道数。但是固定输出通道数修改输入通道数时，延时却随着通道数增长近似
线性地增加（每4个通道一采样）。在阅读过卷积算子的OpenCL内核实现之后，
我们发现卷积算子的内核实现是在输出特征图上划分并行的任务，比如每个线程负责$h\times w\times c$的输出神经元计算，
而每个线程内部则会串行地计算结果。OpenCL的并行能力来源于一组线程（Warp）的同时计算，在这里也就体现为一个区域的
输出神经元的结果计算。因为移动端GPU受限于计算单元（Compute Unit）数量、每线程的私有内存大小、
每线程占有寄存器数量，所以在GPU上一个批次执行的线程数量是有限的。所以当修改输出通道数时，线程数量会增加，
这样的增加要累计到一个批次才能引发延时的大幅度增加。然而修改输入通道数时，每线程的工作量会增加，所以
延时会线性地增长。

\subsubsection{NPU架构硬件的测试与特性分析}
我们预先测量了RK1808计算棒在$1\times 1$卷积算子上的表现。我们发现计算棒不论在固定输入通道数还是在固定输出通道数
的情况下延时都会表现出相对线性的随通道数增长，但是存在许多参数值，延时会大幅度偏离线性的范畴。由于RK1808上的
NPU架构信息偏少，编译器不开源，延时曲线背后的原因暂时没有合理的解释。